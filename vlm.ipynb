{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "0.20.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated random target pos in 5 iterations\n",
      "Reward : 0.9924682378768921\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAMfUlEQVR4nO3dvW4lSRkG4B40OfYVzEoEREgQECMkTMYlmIvbuQQkgp0IiWyTTcl2rmC8KQIdAkuvPLVlTp12/1R1P0/m3ePq6p/jV1XfVPW7y+VymQBgmqZf7N0BAPohFAAIoQBACAUAQigAEEIBgBAKAIRQACCEAgAhFAAIoQBACAUA4n3rBz9++vzVz3/5/S+v/s7fvv/p6me2aqenvrS001Nf5rbj3vbfl5Z2tuzLWu0e8VrNaefx4cPV3zFSACCEAgAhFAAIoQBANBeaW7QUGq8VUGr/v2ynpQizRF9a2pnTxlLtzD2na1rabSlyXWuj1o57W2+jpZ2e+tLSztz+tjx7c57POUZ7FlsYKQAQQgGAEAoARHNNYam5vjnmzNsdsS9Lzcku0e5S3Nu2vtSO1XNftuzPWvdprZpdiz2fRSMFAEIoABBCAYAQCgBEc6F5qUUaSxV8rllqx84ldkVc8vdu1XKf1rq3az0Pe97btXYDnWNOsXfOvd2z4Drn+a39Xs9/m2rtzDnHlmM9Ptxd/R0jBQBCKAAQQgGAmL14bUstc8ijvRFpLXOu1VJztGttmnetL1va6vq2HHuNNlrbWcsS17e1nWu/U7PV35k9GSkAEEIBgBAKAMS7y+Vyafngx0+fb258rX/Tvefc6Za1ibXaXWvtRc/tutftnPf8dnt/xu/u7q5+xkgBgBAKAIRQACCEAgDRXGh+enq6ufE9C0JzjrNWu3OOtVa7c9ve6tqM1v+zPDNzjuWZ2bbdlmM9Pny4+jtGCgCEUAAghAIAMbumsNYijZqe5iaXOE7LsXqbH+7p2D0fZ8tj9XycLY/lnNqPY/EaADcRCgCEUAAghAIAsfvitdKWBaAljt17MbKnY/de3FviuHOP7fque+zRvjtr/eMPi9cAuIlQACCEAgCx6JvX9pxnLJ1h3nGpY5dch2dbznkvdeySe7D9sUs93QOL1wC4iVAAIIQCALFoTaG050ZrpdHWP9QsNc9Y6ql/+vK60efJSz31ZZrO8cyoKQBwE6EAQAgFAEIoABCrFpprjlagOkPxt6an/i3Vl1JPz9k09X0ve7tWpZ76t+d9VGgG4CZCAYAQCgDE5jWF0hnmEGt6nh+uOcPcf+kMtYAa3535eu7bNKkpAHAjoQBACAUAQigAEM2F5qenp5sbV7Ba12j9199n+vtsrf5O03h93qq/jw8frv6OkQIAIRQACKEAQKxaU2gx2hxdafT+T9N457DmXPRLo/XfM/M6z8wzNQUAbiIUAAihAEAMsU6hdIS509IRzmn0Ok6p9/nhFqPfkyN8L0p7PldqCgDcRCgAEEIBgBAKAMTsN68doQC05TmURi9q1RztnBSE38Y5zbfWOSk0A3AToQBACAUAYvMN8bac/3vpiHPrNaPPedbsVfs54jme4dmcpuPVt2rmnKOaAgA3EQoAhFAAIIQCADF78VqLIxaWSqMVmuY6y3m+dIbnd5oU8tfW0729u7u7+jtGCgCEUAAghAIAMcSGeKWe5ui25Ly3dcZznibnvYetztviNQBuIhQACKEAQKy6TmGOM8zrtTjrddjzvEtnvQ6+B8+OeP+tUwDgJkIBgBAKAIRQACDeb31AhcS6sxbU6E/5LO75fNSOvdV3pXacra5Fy3HWug5GCgCEUAAghAIAcZiX7FzT27y5a1PnurzOtalzXV7nJTsAvIlQACCEAgAhFACI5kLz09PTVz/3XlDpiWv1ut6uzUs9Xadp6uta9XZtSq5VnUIzADcRCgCEUAAgmjfEM0dXN/e6/PXP3yzbkVd8+fJlk+NwLuVz39N3cpr63tSvt2tVMlIAIIQCACEUAAihAEBs/ua1OXovzFyzVVG55v7+/upn5hSj12p3S+V9+fa7H3fpR6ueiqelPd+Q1qKna7fnW9VaGCkAEEIBgBAKAMSqb15r0dO8Y839/X+vfOKflf/2u+Ln/1Q+86t5HWIzvddEeqop1PT+3S71fD2XupY2xAPgJkIBgBAKAMTsl+zM1fO8XU05l3d//4+G3/pD8fMPlc/8cWaP2FNPaxnM2a+r9+s753o+Pny4+hkjBQBCKAAQQgGAEAoAxKqF5jMUlur7wv1wcztfvvx2xrF/fvCyELrnZnyllsVgLRvt7amnQnOp98JoabS/D9M0/jVWaAbgJkIBgBAKAMTsmsKI84Gl0ecHe9f79Z1Tv1BTWM5oz3PNaNfchngA3EQoABBCAYAQCgDE+9YPjl4UGq0gNPr1HkG5mK4sPPdcVD6C2ndytOe+7O9of2dqjBQACKEAQAgFAKK5pjCaI8ztwS1q8/GjfQ/K/o5eY5im8e6BkQIAIRQACKEAQKz6kp0tjTb3WBpt3rFm9HtQvpCo5aVAvRv9nhzhe1Ha8554yQ4ANxEKAIRQACCEAgAx5OK10Ytn03TMAhos7QiLwUq9bwRopABACAUAQigAEN3VFHqaW1vK6HOgNUe8T0c0+gZzNUd8sU1P98lIAYAQCgCEUAAghAIA0V2hGbZS7opaur+//9l/O8LOqfRvz8KzkQIAIRQACKEAQOxeUzjCYprSERbTjO5avWCuWp2hpO6wrSNumlfachM9IwUAQigAEEIBgNi8pnDEGgL8Py11iBZL1Cp6f8HLUo64aV5prbUMRgoAhFAAIIQCACEUAIhVC81HLGCVei9g/atS5PxN8fO/GwqYZ7iXS1mqsHytXYvkeGmpf0RgpABACAUAQigAELNrCmedY+69hlD6dWXe+e/F3PSfturMStba/I7jOMNitpo552mkAEAIBQBCKAAQQgGAeHe5XC4tH/z46fNXP5+lUFNSYO/PWovFRvPtdz8u0k7P93pNZ/huPz58uPoZIwUAQigAEEIBgGhevGae8TzOeq8BIwUAXhAKAIRQACBWfcnOaM5YPziC2stmzrB2Yal1CTwra2ln/XtgpABACAUAQigAEEIBgFBo5pDK4vNahecjFnvP+payUu28z1B8NlIAIIQCACEUAIhT1xTOMD/Y4gxzxrUFbtd4PjgjIwUAQigAEEIBgBAKAMRpCs2KhsBbnWEnVSMFAEIoABBCAYA4TU0BmKc2b36GBY8tjlhjMFIAIIQCACEUAIjD1hSOMLe3FvPBwGuMFAAIoQBACAUAQigAEIcpNCssA3ur/SOO0f42GSkAEEIBgBAKAMRhagrAdsp5cgsiXzfapnlGCgCEUAAghAIAIRQAiCELzb0XanqiAAjcwkgBgBAKAIRQACCGqCmoIbAFzxlb6H3TPCMFAEIoABBCAYAYoqYAWxht47Ke1K6VNTLtenr2jBQACKEAQAgFAEIoABDvLpfLpeWDHz99Xrsv0zQpTr2V4uhyPItv41mcb61n7+7u7upnjBQACKEAQAgFAGL3xWvmbQG+VtZjtvw7aaQAQAgFAEIoABBCAYDYvdAMHFNPO3+ObstdaI0UAAihAEAIBQBi85qCxWrLMUcLLM1IAYAQCgCEUAAgVq0pqB8ArGOtTfOMFAAIoQBACAUAQigAEDbEAzZhg7x1LbVpnpECACEUAAihAEAsWlOwWG1d5mCBtRkpABBCAYAQCgCEUAAgZheaFZUB+lb+45THh7urv2OkAEAIBQBCKAAQNsQDdlGrS1qguT8jBQBCKAAQQgGAaK4pWJewLXOrwB6MFAAIoQBACAUAQigAEEIBgBAKAIRQACCEAgBhQzygG+UiWYs4t2ekAEAIBQBCKAAQQgGAUGjuhIIa0AMjBQBCKAAQQgGAEAoAhFAAIIQCACEUAAihAEBYvAZ0q9w1dZos9FybkQIAIRQACKEAQKgp7MS8KNAjIwUAQigAEEIBgBAKAIRQACCEAgAhFAAIoQBAWLwGDKXcJM9C0GUZKQAQQgGAEAoAhJrCBsx5AqMwUgAghAIAIRQACKEAQAgFAEIoABBCAYAQCgCExWvA0MoN8qbJgtG3MFIAIIQCACEUAAg1hRWYzwRGZaQAQAgFAEIoABBCAYAQCgCEUAAghAIAIRQACIvXgMMpN8mzoLSdkQIAIRQACKEAQAgFAEKh+Y0UsIAjMVIAIIQCACEUAIjmmoK587pykQzH4Zk/Dt/TdkYKAIRQACCEAgBhnQJweGV9SI3hdUYKAIRQACCEAgAhFAAIheYbKVABR2akAEAIBQBCKAAQQgGAEAoAhFAAIIQCACEUAAiL14DTqb1Vz8LUZ0YKAIRQACCEAgDx7nK5XPbuBAB9MFIAIIQCACEUAAihAEAIBQBCKAAQQgGAEAoAhFAAIP4HW8KmLIhIff4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import importlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import rx150_env \n",
    "importlib.reload(rx150_env)\n",
    "\n",
    "from rx150_env import RX150Env \n",
    "\n",
    "urdf_path = \"/interbotix_ros_manipulators/interbotix_ros_xsarms/interbotix_xsarm_descriptions/urdf/rx150.urdf\"\n",
    "\n",
    "# print(urdf_path)\n",
    "\n",
    "rx_env = RX150Env(urdf_path,headless=True,image_height=84,image_width=84)\n",
    "\n",
    "rx_env.reset()\n",
    "rx_env.step(np.zeros(6))\n",
    "rx_img = rx_env.render()\n",
    "\n",
    "rw,_ = rx_env.get_reward_and_terminal()\n",
    "print(f\"Reward : {rw}\")\n",
    "\n",
    "rx_env.close()\n",
    "\n",
    "plt.imshow(rx_img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3104],\n",
      "        [0.3134]])\n",
      "tensor([[31.0354, 31.3393]], grad_fn=<TBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "inputs = processor(text=[\"A 3D model of a robot arm and a red dot with a blue end-effector. The robot arm's blue end effector is touching the red dot\",\"A 3D model of a robot arm and a red dot with a blue end-effector.\"], images=rx_img, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "outputs = model(**inputs)\n",
    "logits_per_image = outputs.logits_per_image  # this is the image-text similarity score\n",
    "probs = logits_per_image.softmax(dim=1) \n",
    "\n",
    "# Forward pass through CLIP\n",
    "with torch.no_grad():\n",
    "    text_features = model.get_text_features(**{k: inputs[k] for k in [\"input_ids\", \"attention_mask\"]})\n",
    "    image_features = model.get_image_features(**{k: inputs[k] for k in [\"pixel_values\"]})\n",
    "\n",
    "# Normalize features to unit vectors\n",
    "text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "# Compute cosine similarity manually\n",
    "similarity_score = (text_features @ image_features.T)  # Dot product since vectors are normalized\n",
    "\n",
    "print(similarity_score)\n",
    "\n",
    "print(logits_per_image)\n",
    "# print(probs)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
